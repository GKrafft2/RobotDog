{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time \n",
    "import pyrealsense2 as rs\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_landmark_to_array(landmarks):\n",
    "    landmarks_array = np.array(\n",
    "        [[landmark.x, landmark.y, landmark.z] for landmark in landmarks])\n",
    "    return landmarks_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_output=4):\n",
    "        super().__init__()\n",
    "    \n",
    "        # input = 75x20x3\n",
    "        self.conv1 = nn.Conv2d(n_input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # input = 37x10x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # input = 18x5x64\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # input = 9x2x128\n",
    "        self.fc1 = nn.Linear(128*9*2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, n_output)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2) #maxpool of kernel size 2 to reduce the size of the images by a factor 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128*9*2) #flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = \"trained_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ConvNet().to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT))\n",
    "model.eval()\n",
    "\n",
    "# useful for normalization\n",
    "dataset_mean = np.load(\"dataset_mean.npy\")\n",
    "dataset_std = np.load(\"dataset_std.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51007978,  0.59016526, -0.06745971])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    new_data = np.zeros(data.shape)\n",
    "    new_data[:,:,0] = (data[:,:,0] - dataset_mean[0])/dataset_std[0]\n",
    "    new_data[:,:,1] = (data[:,:,1] - dataset_mean[1])/dataset_std[1]\n",
    "    new_data[:,:,2] = (data[:,:,2] - dataset_mean[2])/dataset_std[2]\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"come\":0,\"lie down\":1,\"sit\":2,\"stay\":3}\n",
    "inv_label_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10633/3701468882.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 40\n",
      "tensor([[5.7739e-04, 3.8005e-01, 6.8228e-04, 6.1869e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 60\n",
      "tensor([[0.0008, 0.4347, 0.0008, 0.5637]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 80\n",
      "tensor([[0.0007, 0.4609, 0.0009, 0.5375]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 100\n",
      "tensor([[0.0007, 0.4465, 0.0009, 0.5520]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 120\n",
      "tensor([[1.0234e-03, 2.0104e-01, 2.5327e-04, 7.9769e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 140\n",
      "tensor([[6.3297e-04, 5.5168e-02, 3.6349e-04, 9.4384e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 160\n",
      "tensor([[2.2451e-04, 1.2395e-01, 1.6380e-04, 8.7566e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 180\n",
      "tensor([[2.6847e-04, 1.4368e-01, 1.0319e-04, 8.5595e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 200\n",
      "tensor([[4.4016e-03, 2.9548e-01, 2.8680e-04, 6.9983e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 220\n",
      "tensor([[3.3899e-04, 9.5625e-02, 5.2277e-04, 9.0351e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 240\n",
      "tensor([[2.1282e-04, 1.5901e-01, 6.4148e-05, 8.4071e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 260\n",
      "tensor([[2.7763e-03, 3.3181e-01, 1.5906e-04, 6.6526e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 280\n",
      "tensor([[1.2339e-03, 2.3219e-01, 1.8235e-04, 7.6639e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 300\n",
      "tensor([[5.4810e-04, 9.1614e-02, 5.1059e-04, 9.0733e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 320\n",
      "tensor([[3.9717e-03, 4.2863e-01, 2.0413e-04, 5.6720e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 340\n",
      "tensor([[2.6466e-04, 7.1831e-02, 3.6508e-04, 9.2754e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 360\n",
      "tensor([[2.6114e-04, 6.6075e-02, 3.5975e-04, 9.3330e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 380\n",
      "tensor([[0.0013, 0.4213, 0.0011, 0.5763]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 400\n",
      "tensor([[3.7022e-04, 1.5050e-01, 3.0767e-04, 8.4882e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 420\n",
      "tensor([[9.7048e-05, 3.2789e-02, 2.2512e-04, 9.6689e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 440\n",
      "tensor([[2.0279e-04, 1.0024e-01, 2.3139e-04, 8.9932e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 460\n",
      "tensor([[0.0012, 0.3012, 0.0014, 0.6962]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 480\n",
      "tensor([[4.2618e-05, 5.3845e-02, 1.3473e-04, 9.4598e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 500\n",
      "tensor([[0.0024, 0.6975, 0.0015, 0.2986]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 520\n",
      "tensor([[0.0032, 0.7452, 0.0036, 0.2480]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 540\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 560\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 580\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 600\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 620\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 640\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 660\n",
      "tensor([[0.0237, 0.9523, 0.0029, 0.0210]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 680\n",
      "tensor([[0.0367, 0.8863, 0.0038, 0.0733]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 700\n",
      "tensor([[0.0487, 0.7492, 0.0111, 0.1910]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 720\n",
      "tensor([[0.1208, 0.6875, 0.0056, 0.1861]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 740\n",
      "tensor([[0.0580, 0.7489, 0.0079, 0.1852]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 760\n",
      "tensor([[0.0597, 0.7320, 0.0069, 0.2014]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 780\n",
      "tensor([[0.0474, 0.8374, 0.0104, 0.1049]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 800\n",
      "tensor([[0.0730, 0.7322, 0.0070, 0.1878]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 820\n",
      "tensor([[0.0372, 0.9315, 0.0023, 0.0290]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 840\n",
      "tensor([[0.0442, 0.8471, 0.0062, 0.1025]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 860\n",
      "tensor([[0.0625, 0.7450, 0.0137, 0.1788]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 880\n",
      "tensor([[0.0775, 0.8880, 0.0096, 0.0248]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 900\n",
      "tensor([[0.0639, 0.8476, 0.0065, 0.0820]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 920\n",
      "tensor([[0.0743, 0.7549, 0.0218, 0.1490]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 940\n",
      "tensor([[0.0462, 0.8380, 0.0057, 0.1101]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 960\n",
      "tensor([[0.0489, 0.6905, 0.0128, 0.2478]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 980\n",
      "tensor([[0.0497, 0.6652, 0.0106, 0.2745]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1000\n",
      "tensor([[0.0509, 0.7727, 0.0115, 0.1649]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1020\n",
      "tensor([[0.0418, 0.8372, 0.0064, 0.1146]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1040\n",
      "tensor([[0.0490, 0.6701, 0.0137, 0.2671]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1060\n",
      "tensor([[0.0591, 0.7200, 0.0153, 0.2056]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1080\n",
      "tensor([[0.0561, 0.7459, 0.0129, 0.1850]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1100\n",
      "tensor([[0.0380, 0.9322, 0.0032, 0.0266]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1120\n",
      "tensor([[0.0524, 0.6865, 0.0166, 0.2444]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1140\n",
      "tensor([[0.0608, 0.7231, 0.0121, 0.2040]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1160\n",
      "tensor([[0.0339, 0.9242, 0.0051, 0.0367]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1180\n",
      "tensor([[0.0536, 0.9171, 0.0021, 0.0273]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1200\n",
      "tensor([[0.0102, 0.6550, 0.0068, 0.3280]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1220\n",
      "tensor([[0.7152, 0.2116, 0.0376, 0.0356]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1240\n",
      "tensor([[0.0058, 0.3847, 0.0025, 0.6070]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1260\n",
      "tensor([[0.0585, 0.4816, 0.0071, 0.4528]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1280\n",
      "tensor([[0.0931, 0.6178, 0.0146, 0.2746]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1300\n",
      "tensor([[0.0780, 0.7822, 0.0098, 0.1301]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1320\n",
      "tensor([[0.0882, 0.7798, 0.0064, 0.1256]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1340\n",
      "tensor([[0.0358, 0.9420, 0.0038, 0.0184]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1360\n",
      "tensor([[0.0813, 0.7670, 0.0100, 0.1417]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1380\n",
      "tensor([[0.0809, 0.7660, 0.0105, 0.1425]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1400\n",
      "tensor([[0.1119, 0.8406, 0.0042, 0.0432]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1420\n",
      "tensor([[0.1390, 0.8091, 0.0034, 0.0484]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1440\n",
      "tensor([[0.0744, 0.8098, 0.0059, 0.1099]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1460\n",
      "tensor([[0.0768, 0.6985, 0.0216, 0.2031]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1480\n",
      "tensor([[0.0829, 0.7634, 0.0150, 0.1387]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1500\n",
      "tensor([[0.0876, 0.7476, 0.0131, 0.1517]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1520\n",
      "tensor([[0.0666, 0.8109, 0.0058, 0.1167]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1540\n",
      "tensor([[0.0719, 0.8292, 0.0057, 0.0932]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1560\n",
      "tensor([[0.0901, 0.7562, 0.0131, 0.1406]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1580\n",
      "tensor([[0.0729, 0.8280, 0.0060, 0.0932]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1600\n",
      "tensor([[0.0941, 0.7537, 0.0128, 0.1394]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1620\n",
      "tensor([[0.0721, 0.8515, 0.0052, 0.0712]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1640\n",
      "tensor([[0.0930, 0.7425, 0.0117, 0.1528]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1660\n",
      "tensor([[0.0763, 0.8302, 0.0060, 0.0875]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1680\n",
      "tensor([[0.1055, 0.7509, 0.0078, 0.1358]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1700\n",
      "tensor([[0.1026, 0.7317, 0.0076, 0.1581]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1720\n",
      "tensor([[0.0918, 0.7447, 0.0075, 0.1560]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1740\n",
      "tensor([[0.0874, 0.7488, 0.0075, 0.1563]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1760\n",
      "tensor([[0.0816, 0.8406, 0.0046, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1780\n",
      "tensor([[0.0513, 0.9122, 0.0027, 0.0339]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1800\n",
      "tensor([[0.0568, 0.8145, 0.0143, 0.1144]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1820\n",
      "tensor([[0.0661, 0.8027, 0.0060, 0.1253]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1840\n",
      "tensor([[0.0620, 0.8013, 0.0064, 0.1303]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1860\n",
      "tensor([[0.0538, 0.8910, 0.0036, 0.0516]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1880\n",
      "tensor([[0.0513, 0.8081, 0.0062, 0.1344]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1900\n",
      "tensor([[0.1326, 0.8266, 0.0059, 0.0350]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1920\n",
      "tensor([[0.1093, 0.8368, 0.0013, 0.0526]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "frame 1940\n",
      "tensor([[0.6932, 0.2463, 0.0412, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_frame_time = 0\n",
    "prev_frame_time = 0\n",
    "\n",
    "predicted_class_name = \"hee\"\n",
    "\n",
    "\n",
    "# could find a way of finding this value automatically\n",
    "frames_by_sec = 20 - 1\n",
    "n_frames = 0\n",
    "landmark_image = np.empty((75,3))\n",
    "\n",
    "#hollistic detects posiiton, face and hand landmarks\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "moves = [\"sit\", \"lie down\", \"stay\", \"come\"]\n",
    "\n",
    "\n",
    "n_samples = 30 # number of times we will record each move\n",
    "current_sample = 0 # current sample we are recording\n",
    "current_move = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    n_frames += 1\n",
    "\n",
    "    if n_frames > 20:\n",
    "      if n_frames % 20 == 0:\n",
    "        # convert to tensor\n",
    "        data = landmark_image[:,:,-20:]\n",
    "        data = np.transpose(data, (0, 2, 1))\n",
    "        data = np.transpose(data, (2, 0, 1))\n",
    "        data = np.nan_to_num(data)\n",
    "        data = np.clip(data, -10, 10)\n",
    "        # print(\"before normalization\")\n",
    "        # print(data)\n",
    "        data = normalize_data(data)\n",
    "        # print(\"after normalization\")\n",
    "        # print(data)\n",
    "        data = torch.tensor(data).float() \n",
    "        # print(data.shape)\n",
    "        # data = data.transpose(1,0,2)\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        # print(data.shape)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # predict\n",
    "        output = model.predict(data)\n",
    "        print(f\"frame {n_frames}\")\n",
    "        print(output)\n",
    "        # get the predicted class\n",
    "        if torch.max(output) > 0.8:\n",
    "          predicted_class = torch.argmax(output, dim=1)\n",
    "          predicted_class_name = inv_label_dict[int(predicted_class)]\n",
    "\n",
    "    # compute fps\n",
    "    new_frame_time = time.time()\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "\n",
    "    # compute keypoints etc...\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # convert landmarks to array with exception handling (zero array if not detected)\n",
    "    try:\n",
    "      pose_landmarks = convert_landmark_to_array(results.pose_landmarks.landmark)\n",
    "    except:\n",
    "      #  print(\"no pose landmarks detected\")\n",
    "       pose_landmarks = np.zeros((33,3))\n",
    "    try:\n",
    "      left_hand_landmarks = convert_landmark_to_array(results.left_hand_landmarks.landmark)\n",
    "    except:\n",
    "      # print(\"no left hand landmarks detected\")\n",
    "      left_hand_landmarks = np.zeros((21,3))\n",
    "    try:\n",
    "      right_hand_landmarks = convert_landmark_to_array(results.right_hand_landmarks.landmark)\n",
    "    except:\n",
    "      # print(\"no right hand landmarks detected\")\n",
    "      right_hand_landmarks = np.zeros((21,3))\n",
    "\n",
    "    hands_and_pose_array = np.concatenate((pose_landmarks, left_hand_landmarks, right_hand_landmarks), axis=0)\n",
    "    landmark_image = np.dstack((landmark_image, hands_and_pose_array))\n",
    "\n",
    "    # Drawing the annotiations\n",
    "    image.flags.writeable = True\n",
    "    \n",
    "    # Drawing Pose Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    \n",
    "    # Drawing Right hand Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.right_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    " \n",
    "    # Drawing Left hand Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.left_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    "\n",
    "    fps = str(int(fps))\n",
    "    image = cv2.flip(image,1)\n",
    "    cv2.putText(image, fps, (7, 70), 1, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(image, predicted_class_name, (7, 100), 1, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "    cv2.imshow('image', image)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: # press escape to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.57543206  0.57580936  0.57713217 ...  0.55239332  0.55198002\n",
      "    0.55117744]\n",
      "  [ 0.41942284  0.42004308  0.41875026 ...  0.40985876  0.41184559\n",
      "    0.41329852]\n",
      "  [-1.30985749 -1.29141164 -1.29826665 ... -1.35136628 -1.53660369\n",
      "   -1.53420484]]\n",
      "\n",
      " [[ 0.60451788  0.60545415  0.60664648 ...  0.59008121  0.58919567\n",
      "    0.58810782]\n",
      "  [ 0.35109404  0.35150319  0.34848031 ...  0.34219816  0.34510046\n",
      "    0.3467674 ]\n",
      "  [-1.2514509  -1.23845208 -1.24429297 ... -1.29650843 -1.48042607\n",
      "   -1.47882533]]\n",
      "\n",
      " [[ 0.61746204  0.61828625  0.61942834 ...  0.60547167  0.60470277\n",
      "    0.60366195]\n",
      "  [ 0.35463998  0.35508117  0.35389078 ...  0.34539926  0.34830007\n",
      "    0.34978008]\n",
      "  [-1.25121236 -1.23813081 -1.24394679 ... -1.29606998 -1.47994792\n",
      "   -1.47841942]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(landmark_image[:,:,40:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
